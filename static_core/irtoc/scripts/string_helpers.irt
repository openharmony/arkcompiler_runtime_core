#!/usr/bin/env ruby

# Copyright (c) 2021-2026 Huawei Device Co., Ltd.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

macro(:load_diff) do |ptr1, ptr2, offset|
    Xor(LoadI(ptr1).Imm(Constants::STRING_DATA_OFFSET + " + " + offset.to_s).u64,
        LoadI(ptr2).Imm(Constants::STRING_DATA_OFFSET + " + " + offset.to_s).u64).u64
end  # load_diff

###
# get_string_length extracts the string length (the number of characters, not the size in bytes)
# from the corresponding length field.
#
macro(:get_string_length) do |length, length_shift|
    ShrI(length).Imm(length_shift).u64
end  # get_string_length

# TODO `unpack_length_with_compression` is the replacement for this when the support for strings without
# compression is removed from the code of all the string-related intrinsics.
scoped_macro(:unpack_length) do |length, compression, length_shift|
    if compression
        unpack_length_with_compression(length, length_shift)
    elsif length_shift != 0
        get_string_length(length, length_shift)
    end
end  # unpack_length

scoped_macro(:unpack_length_with_compression) do |length, length_shift|
  char_length := get_string_length(length, length_shift)
  uncompressed := is_string_uncompressed_u64(length)
  unpacked_length := Shl(char_length, uncompressed).u64
end  # unpack_length_with_compression

###
# is_string_uncompressed returns the inverted value of the `compressed` flag. The flag's value is encoded
# as the least significant bit in the `length` field of the string object.
#
# More details may be found in the `bool BaseString::IsUtf8()` and `bool BaseString::IsUtf16()` method implementation
# in the `runtime_core/common_interfaces/objects/string/base_string.h` header.
#
["u32", "u64"].each do |ret_type|
  scoped_macro("is_string_uncompressed_#{ret_type}".to_sym) do |length|
    AndI(length).Imm(1).send(ret_type)
  end  # is_string_uncompressed_#{ret_type}
end

scoped_macro(:check_string_type) do |str, slowpath|
  baseClass := load_class(str)
  stringType := LoadI(baseClass).Imm(Constants::STRING_TYPE_OFFSET).u64
  If(stringType, Constants::STRING_TYPE_SLICE).EQ {
    GotoGlobal(slowpath)
  }
  If(stringType, Constants::STRING_TYPE_TREE).EQ {
    GotoGlobal(slowpath)
  }
end  # check_string_type

scoped_macro(:get_tree_data_ptr) do |tree_str, cache_miss_label|
  stringCache := LoadI(%tr).Imm(Constants::THREAD_FLATTENED_STRING_CACHE_OFFSET).ref
  If(stringCache, 0).EQ {
    GotoGlobal(cache_miss_label)
  }
  # cannot cast directly from ref to uint
  strPtr := Cast(tree_str).ptr
  strUint := Bitcast(strPtr).word
  strShifted := ShrI(strUint).Imm(FlattenedStringCacheConstants::ADDRESS_SHIFT).word
  strMasked := AndI(strShifted).Imm(FlattenedStringCacheConstants::ADDRESS_MASK).word
  strIndex := Mul(strMasked, FlattenedStringCacheConstants::ENTRY_SIZE).word
  key := LoadArray(stringCache, strIndex).SetNeedBarrier(true).ref
  If(key, tree_str).NE {
    GotoGlobal(cache_miss_label)
  }
  strIndex := AddI(strIndex).Imm(FlattenedStringCacheConstants::VALUE_OFFSET).ref_uint
  strCached := LoadArray(stringCache, strIndex).SetNeedBarrier(true).ref
  data_ptr := AddI(Cast(strCached).SrcType(Constants::COMPILER_REFERENCE).ptr).Imm(Constants::STRING_DATA_OFFSET).ptr
end


scoped_macro(:get_sliced_data_ptr) do |sliced_str, length_packed|
  # According to the specification the parent string must always be LineString.
  parent := LoadI(sliced_str).Imm(Constants::SLICED_STRING_PARENT_OFFSET).SetNeedBarrier(true).ref
  uncompressed := is_string_uncompressed_u64(length_packed)
  startIndex := LoadI(sliced_str).Imm(Constants::SLICED_STRING_STARTINDEX_AND_FLAGS_OFFSET).u32
  startIndex := ShrI(startIndex).Imm(Constants::SLICED_STRING_STARTINDEX_SHIFT).u64
  offset := Shl(startIndex, uncompressed).u64
  data_ptr := AddI(Cast(parent).SrcType(Constants::COMPILER_REFERENCE).ptr).Imm(Constants::STRING_DATA_OFFSET).ptr
  data_ptr := Add(data_ptr, offset).ptr
end


scoped_macro(:dispatch_on_string_type) do |str, line_label, sliced_label, tree_label|
  baseClass := load_class(str)
  stringType := LoadI(baseClass).Imm(Constants::STRING_TYPE_OFFSET).u64
  If(stringType, Constants::STRING_TYPE_LINE).EQ {
    GotoGlobal(line_label)
  }
  If(stringType, Constants::STRING_TYPE_SLICE).EQ {
    GotoGlobal(sliced_label)
  }
  If(stringType, Constants::STRING_TYPE_TREE).EQ {
    GotoGlobal(tree_label)
  }
  Intrinsic(:UNREACHABLE).Terminator.void
end


module FlattenedStringCacheConstants
  ADDRESS_SHIFT = "cross_values::GetFlattenedStringCacheAddressShift(GetArch())"
  ADDRESS_MASK = "cross_values::GetFlattenedStringCacheAddressMask(GetArch())"
  ENTRY_SIZE = "cross_values::GetFlattenedStringCacheEntrySize(GetArch())"
  VALUE_OFFSET = "cross_values::GetFlattenedStringCacheValueOffset(GetArch())"
end

macro(:check_not_tree_string_type) do |str|
  baseClass := load_class(str)
  stringType := LoadI(baseClass).Imm(Constants::STRING_TYPE_OFFSET).u64
  If(stringType, Constants::STRING_TYPE_TREE).EQ {
    Intrinsic(:UNREACHABLE).void.Terminator
  }
end

scoped_macro(:try_get_flattened_tree_str) do |str, slowpath|
  stringCache := LoadI(%tr).Imm(Constants::THREAD_FLATTENED_STRING_CACHE_OFFSET).ref
  If(stringCache, 0).EQ {
    GotoGlobal(slowpath)
  }

  # cannot cast directly from ref to uint
  strPtr := Cast(str).ptr
  strUint := Bitcast(strPtr).word
  strShifted := ShrI(strUint).Imm(FlattenedStringCacheConstants::ADDRESS_SHIFT).word
  strMasked := AndI(strShifted).Imm(FlattenedStringCacheConstants::ADDRESS_MASK).word
  strIndex := Mul(strMasked, FlattenedStringCacheConstants::ENTRY_SIZE).word
  key := LoadArray(stringCache, strIndex).SetNeedBarrier(true).ref
  If(key, str).NE {
    GotoGlobal(slowpath)
  }
  strIndex := AddI(strIndex).Imm(FlattenedStringCacheConstants::VALUE_OFFSET).ref_uint
  strCached := LoadArray(stringCache, strIndex).SetNeedBarrier(true).ref
end  # try_get_flattened_tree_str

scoped_macro(:try_use_cached_flat_str_reject_sliced) do |str, slowpath|
  baseClass := load_class(str)
  stringType := LoadI(baseClass).Imm(Constants::STRING_TYPE_OFFSET).u64
  If(stringType, Constants::STRING_TYPE_SLICE).EQ {
    GotoGlobal(slowpath)
  }
  If(stringType, Constants::STRING_TYPE_TREE).EQ {
    strCached := try_get_flattened_tree_str(str, slowpath)
  }
  result := Phi(str, strCached).ref
end  # try_use_cached_flat_str_reject_sliced

scoped_macro(:try_use_cached_flat_str_accept_sliced) do |str, slowpath|
  baseClass := load_class(str)
  stringType := LoadI(baseClass).Imm(Constants::STRING_TYPE_OFFSET).u64
  If(stringType, Constants::STRING_TYPE_TREE).EQ {
    strCached := try_get_flattened_tree_str(str, slowpath)
  }
  result := Phi(str, strCached).ref
end  # try_use_cached_flat_str_accept_sliced

macro(:load_core_string_class) do ||
  _string_klass := LoadI(%tr).Imm(Constants::CORE_STRING_CLASS_OFFSET).ref
end

# Try to allocate String in TLAB.
# The result is either a pointer to a new string or null if there is no enough space in TLAB.
macro(:allocate_string_tlab) do |string_klass, data_size, cgmode|
  if Options.arch == :arm32
    Intrinsic(:UNREACHABLE).Terminator.void
    ReturnVoid().void
    next
  end

  # Add sizeof(String) and do align
  _data_size := Cast(data_size).word
  _size := AndI(AddI(_data_size).Imm(Constants::STRING_CLASS_SIZE_WITH_ALIGNMENT).word).Imm(Constants::ALIGNMENT_MASK).word
  # Load pointer to the TLAB from TLS
  _tlab := LoadI(%tr).Imm(Constants::TLAB_OFFSET).ptr
  # Load pointer to the start address of free memory in the TLAB
  _start := LoadI(_tlab).Imm(Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr
  # Load pointer to the end address of free memory in the TLAB
  _end := LoadI(_tlab).Imm(Constants::TLAB_MEMORY_END_ADDR_OFFSET).ptr
  # Check if there is enough space
  If(Sub(_end, _start).word, _size).B.Unlikely.b {
    Goto(:SlowPathEntrypoint)
  }

  if cgmode == :FastPath
    Intrinsic(:WRITE_TLAB_STATS_SAFE, _start, _size, Cast(-1).u64).void if defines.DEBUG
  else
    Call(_start, _size, Cast(-1).u64).Method('WriteTlabStatsEntrypoint').void if defines.DEBUG
  end

  if defines.__SANITIZE_ADDRESS__ || defines.__SANITIZE_THREAD__
    if cgmode == :FastPath
      call_runtime_save_all(Constants::ANNOTATE_SANITIZERS_NO_BRIDGE, _start, _size).void
    else
      Call(_start, _size).Method('AnnotateSanitizersEntrypoint').void
    end
  end
  # Store class of the object
  store_class(_start, string_klass)
  # Update the TLAB state
  StoreI(Add(_tlab, Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr, Add(_start, _size).ptr).Imm(0).ptr
  # Return a pointer to the newly allocated string
  _allocated_string := _start
end  # allocate_string_tlab

macro(:allocate_tree_string_tlab) do |tree_string_klass|
  if Options.arch == :arm32
    Intrinsic(:UNREACHABLE).Terminator.void
    ReturnVoid().void
    next
  end

  # Add sizeof(String) and do align
  _size := Cast(Constants::TREE_STRING_ALIGNED_OBJ_SIZE).word
  _size := AndI(_size).Imm(Constants::ALIGNMENT_MASK).word
  # Load pointer to the TLAB from TLS
  _tlab := LoadI(%tr).Imm(Constants::TLAB_OFFSET).ptr
  # Load pointer to the start address of free memory in the TLAB
  _start := LoadI(_tlab).Imm(Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr
  # Load pointer to the end address of free memory in the TLAB
  _end := LoadI(_tlab).Imm(Constants::TLAB_MEMORY_END_ADDR_OFFSET).ptr
  # Check if there is enough space
  If(Sub(_end, _start).word, _size).B.Unlikely.b {
    Goto(:SlowPathEntrypoint)
  }
  Intrinsic(:WRITE_TLAB_STATS_SAFE, _start, _size, Cast(-1).u64).void if defines.DEBUG
  if defines.__SANITIZE_ADDRESS__ || defines.__SANITIZE_THREAD__
    call_runtime_save_all(Constants::ANNOTATE_SANITIZERS_NO_BRIDGE, _start, _size).void
  end
  # Store class of the object
  store_class(_start, tree_string_klass)
  # Update the TLAB state
  StoreI(Add(_tlab, Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr, Add(_start, _size).ptr).Imm(0).ptr
  # Return a pointer to the newly allocated string
  _allocated_string := _start
end

macro(:allocate_sliced_string_tlab) do |sliced_string_klass|
  if Options.arch == :arm32
    Intrinsic(:UNREACHABLE).Terminator.void
    ReturnVoid().void
    next
  end

  # Add sizeof(String) and do align
  _size := Cast(Constants::SLICED_STRING_ALIGNED_OBJ_SIZE).word
  _size := AndI(_size).Imm(Constants::ALIGNMENT_MASK).word
  # Load pointer to the TLAB from TLS
  _tlab := LoadI(%tr).Imm(Constants::TLAB_OFFSET).ptr
  # Load pointer to the start address of free memory in the TLAB
  _start := LoadI(_tlab).Imm(Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr
  # Load pointer to the end address of free memory in the TLAB
  _end := LoadI(_tlab).Imm(Constants::TLAB_MEMORY_END_ADDR_OFFSET).ptr
  # Check if there is enough space
  If(Sub(_end, _start).word, _size).B.Unlikely.b {
    Goto(:SlowPathEntrypoint)
  }
  Intrinsic(:WRITE_TLAB_STATS_SAFE, _start, _size, Cast(-1).u64).void if defines.DEBUG
  if defines.__SANITIZE_ADDRESS__ || defines.__SANITIZE_THREAD__
    call_runtime_save_all(Constants::ANNOTATE_SANITIZERS_NO_BRIDGE, _start, _size).void
  end
  # Store class of the object
  store_class(_start, sliced_string_klass)
  # Update the TLAB state
  StoreI(Add(_tlab, Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr, Add(_start, _size).ptr).Imm(0).ptr
  # Return a pointer to the newly allocated string
  _allocated_string := _start
end  # allocate_sliced_string_tlab

# Try to allocate String in TLAB.
# The result is either a pointer to a new string or null if there is no enough space in TLAB.
# this is a version that does not do allocation tracking due to the bug #24977
macro(:allocate_string_tlab_no_debug) do |string_klass, data_size|
  if Options.arch == :arm32
    Intrinsic(:UNREACHABLE).Terminator.void
    ReturnVoid().void
    next
  end

  # Add sizeof(String) and do align
  _data_size := Cast(data_size).word
  _size := AndI(AddI(_data_size).Imm(Constants::STRING_CLASS_SIZE_WITH_ALIGNMENT).word).Imm(Constants::ALIGNMENT_MASK).word
  # Load pointer to the TLAB from TLS
  _tlab := LoadI(%tr).Imm(Constants::TLAB_OFFSET).ptr
  # Load pointer to the start address of free memory in the TLAB
  _start := LoadI(_tlab).Imm(Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr
  # Load pointer to the end address of free memory in the TLAB
  _end := LoadI(_tlab).Imm(Constants::TLAB_MEMORY_END_ADDR_OFFSET).ptr
  # Check if there is enough space
  If(Sub(_end, _start).word, _size).B.Unlikely.b {
    Goto(:SlowPathEntrypoint)
  }
  if defines.__SANITIZE_ADDRESS__ || defines.__SANITIZE_THREAD__
    call_runtime_save_all(Constants::ANNOTATE_SANITIZERS_NO_BRIDGE, _start, _size).void
  end
  # Store class of the object
  StoreI(_start, string_klass).Imm(Constants::OBJECT_CLASS_OFFSET).ref
  # Update the TLAB state
  StoreI(Add(_tlab, Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr, Add(_start, _size).ptr).Imm(0).Volatile.ptr
  # Return a pointer to the newly allocated string
  _allocated_string := _start
end  # allocate_string_tlab_no_debug

# Try to allocate Array of i8 chars in TLAB.
# The result is either a pointer to a new array or null if there is no enough space in TLAB.
macro(:allocate_array_of_bytes_tlab) do |array_klass_dummy, char_count, cgmode|
  if Options.arch == :arm32
    Intrinsic(:UNREACHABLE).Terminator.void
    ReturnVoid().void
    next
  end

  array_klass := LoadI(%tr).Imm(Constants::BYTE_ARRAY_CLASS_OFFSET).ref
  elements_num := And(char_count, "0x00000000ffffffff").word
  # Account for u16 char size
  _size := Cast(elements_num).word
  # Add sizeof(Array) and do align
  _size := AndI(AddI(_size).Imm(Constants::ARRAY_CLASS_SIZE_WITH_ALIGNMENT).word).Imm(Constants::ALIGNMENT_MASK).word
  # Load pointer to the TLAB from TLS
  _tlab := LoadI(%tr).Imm(Constants::TLAB_OFFSET).ptr
  # Load pointer to the start address of free memory in the TLAB
  _start := LoadI(_tlab).Imm(Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr
  # Load pointer to the end address of free memory in the TLAB
  _end := LoadI(_tlab).Imm(Constants::TLAB_MEMORY_END_ADDR_OFFSET).ptr
  # Check if there is enough space
  If(Sub(_end, _start).word, _size).B.Unlikely.b {
    Goto(:SlowPathEntrypoint)
  }
  if cgmode == :FastPath
    Intrinsic(:WRITE_TLAB_STATS_SAFE, _start, _size, Cast(-1).u64).void if defines.DEBUG
  else
    Call(_start, _size, Cast(-1).u64).Method('WriteTlabStatsEntrypoint').void if defines.DEBUG
  end
  if defines.__SANITIZE_ADDRESS__ || defines.__SANITIZE_THREAD__
    if cgmode == :FastPath
      call_runtime_save_all(Constants::ANNOTATE_SANITIZERS_NO_BRIDGE, _start, _size).void
    else
      Call(_start, _size).Method('AnnotateSanitizersEntrypoint').void
    end
  end
  # Store class of the object
  store_class(_start, array_klass)
  # Store array length
  StoreI(_start, elements_num).Imm(Constants::ARRAY_LENGTH_OFFSET).word
  # Update the TLAB state
  StoreI(Add(_tlab, Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr, Add(_start, _size).ptr).Imm(0).Volatile.ptr
  # Return a pointer to the newly allocated array
  _allocated_array := _start
end  # allocate_array_of_bytes_tlab

# Try to allocate Array of u16 chars in TLAB.
# The result is either a pointer to a new array or null if there is no enough space in TLAB.
macro(:allocate_array_of_chars_tlab) do |array_klass_dummy, char_count, cgmode|
  if Options.arch == :arm32
    Intrinsic(:UNREACHABLE).Terminator.void
    ReturnVoid().void
    next
  end

  array_klass := LoadI(%tr).Imm(Constants::CHAR_ARRAY_CLASS_OFFSET).ref

  elements_num := AndI(char_count).Imm(0xffffffff).word
  _size := ShlI(char_count).Imm(1).word
  # Account for u16 char size
  # Add sizeof(Array) and do align
  _size := AndI(AddI(_size).Imm(Constants::ARRAY_CLASS_SIZE_WITH_ALIGNMENT).word).Imm(Constants::ALIGNMENT_MASK).word
  # Load pointer to the TLAB from TLS
  _tlab := LoadI(%tr).Imm(Constants::TLAB_OFFSET).ptr
  # Load pointer to the start address of free memory in the TLAB
  _start := LoadI(_tlab).Imm(Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr
  # Load pointer to the end address of free memory in the TLAB
  _end := LoadI(_tlab).Imm(Constants::TLAB_MEMORY_END_ADDR_OFFSET).ptr
  # Check if there is enough space
  If(Sub(_end, _start).word, _size).B.Unlikely.b {
    Goto(:SlowPathEntrypoint)
  }
  if cgmode == :FastPath
    Intrinsic(:WRITE_TLAB_STATS_SAFE, _start, _size, Cast(-1).u64).void if defines.DEBUG
  else
    Call(_start, _size, Cast(-1).u64).Method('WriteTlabStatsEntrypoint').void if defines.DEBUG
  end
  if defines.__SANITIZE_ADDRESS__ || defines.__SANITIZE_THREAD__
    if cgmode == :FastPath
      call_runtime_save_all(Constants::ANNOTATE_SANITIZERS_NO_BRIDGE, _start, _size).void
    else
      Call(_start, _size).Method('AnnotateSanitizersEntrypoint').void
    end
  end
  # Store class of the object
  store_class(_start, array_klass)
  # Store array length
  StoreI(_start, elements_num).Imm(Constants::ARRAY_LENGTH_OFFSET).word
  # Update the TLAB state
  StoreI(Add(_tlab, Constants::TLAB_CUR_FREE_POSITION_OFFSET).ptr, Add(_start, _size).ptr).Imm(0).ptr
  # Return a pointer to the newly allocated array
  _allocated_array := _start
end  # allocate_array_of_chars_tlab

###
# Compute string hashcode
#
scoped_macro(:u8_string_hashcode) do |str_data, char_count|
  hash := Cast(0).u32
  If(char_count, 0).A.Likely.b {
    i1 := Cast(0).u32
    imm31 := Cast(31).u32
Label(:Loop_hash)
    hash1 := Phi(hash, hash2).u32
    i := Phi(i1, i2).u32
    ch := Cast(Load(str_data, i).u8).SrcType(Constants::COMPILER_UINT8).u32
    hash2 := Add(Mul(hash1, imm31).u32, ch).u32
    i2 := AddI(i).Imm(1).u32
    If(i2, char_count).B.Likely.b {
      Goto(:Loop_hash)
    }
  }
  hashcode := Phi(hash, hash2).u32
end  # u8_string_hashcode

scoped_macro(:u16_string_hashcode) do |str_data, char_count|
  hash := Cast(0).u32
  If(char_count, 0).A.Likely.b {
    i1 := Cast(0).u64
    imm31 := Cast(31).u32
    stop := ShlI(Cast(char_count).u64).Imm(1).u64
Label(:Loop_hash)
    hash1 := Phi(hash, hash2).u32
    i := Phi(i1, i2).u64
    ch := Cast(Load(str_data, i).u16).SrcType(Constants::COMPILER_UINT16).u32
    hash2 := Add(Mul(hash1, imm31).u32, ch).u32
    i2 := AddI(i).Imm(2).u64
    If(i2, stop).B.Likely.b {
      Goto(:Loop_hash)
    }
  }
  hashcode := Phi(hash, hash2).u32
end  # u16_string_hashcode

###
# Checks if starting from arr_data the specified number of chars (char_count) can be compressed
#
# Utf16 char is ASCII if (utf16_char - 1U < utf::UTF8_1B_MAX)
# See runtime/include/coretypes/string.h - IsASCIICharacter
#
scoped_macro(:is_array_of_compressable_chars) do |arr_data, char_count|
  # Check 4-chars block at once if it's possible
  n_blocks := ShrI(char_count).Imm(2).u64
  If(n_blocks, 0).A.Likely.b {
    # 0x007F is utf::UTF8_1B_MAX
    utf8_1b_max := Cast(0x007F007F007F007F).u64
    utf8_1b_max_mask := Not(utf8_1b_max).u64
    i1 := Cast(0).u64
  Label(:CanBeCompressedLoop_4chars)
    i2 := Phi(i1, i3).u64
    four_chars := Load(arr_data, ShlI(i2).Imm(3).u64).u64
    # First: check if there are chars greater than utf::UTF8_1B_MAX
    If(And(four_chars, utf8_1b_max_mask).u64, 0).NE.Unlikely.b {
        compressable1 := Cast(0).b
        Goto(:CanBeCompressedLoopDone)
    }
    # Second: check if there are chars equal to zero
    If(And(SubI(four_chars).Imm(0x0001000100010001).u64, utf8_1b_max_mask).u64, 0).NE.Unlikely.b {
        compressable2 := Cast(0).b
        Goto(:CanBeCompressedLoopDone)
    }
    i3 := AddI(i2).Imm(1).u64
    If(i3, n_blocks).B.Likely.b {
        Goto(:CanBeCompressedLoop_4chars)
    }
  }
  # check the rest of the chars
  If(AndI(char_count).Imm(3).u64, 0).A.Likely.b {
    i4 := ShlI(n_blocks).Imm(2).u64  # number of already copied chars if any
Label(:CanBeCompressedLoop)
    i5 := Phi(i4, i6).u64
    ch := Load(arr_data, ShlI(i5).Imm(1).u64).u16
    If(SubI(ch).Imm(Constants::STRING_MUTF8_1B_MIN).u16, Cast(Constants::STRING_MUTF8_1B_MAX).u16).AE.Unlikely.b {
      compressable3 := Cast(0).b
      Goto(:CanBeCompressedLoopDone)
    }
    i6 := AddI(i5).Imm(1).u64
    If(i6, char_count).B.Likely.b {
      Goto(:CanBeCompressedLoop)
    }
  }
  compressable4 := Cast(1).b
Label(:CanBeCompressedLoopDone)
  compressable := Phi(compressable1, compressable2, compressable3, compressable4).b
end  # is_array_of_compressable_chars


###
# Copy u16 chars compressing them to u8.
# It is assumed that all u16 chars are compressable.
#
scoped_macro(:compress_u16_to_u8_chars) do |src_data, dst_data, char_count|
if Options.arch == :arm64
  # Copy 32-byte chunks (if any) compressing them into 16-byte chunks
  If(char_count, 16).AE.Likely.b {
    stop := Add(src_data, ShlI(ShrI(char_count).Imm(4).u64).Imm(5).u64).ptr
Label(:CopyLoop_32b)
    src_data1 := Phi(src_data, src_data2).ptr
    dst_data1 := Phi(dst_data, dst_data2).ptr
    Intrinsic(:COMPRESS_SIXTEEN_UTF16_TO_UTF8_CHARS_USING_SIMD, src_data1, dst_data1).void
    src_data2 := AddI(src_data1).Imm(32).ptr
    dst_data2 := AddI(dst_data1).Imm(16).ptr
    If(src_data2, stop).LT.Likely.b {
      Goto(:CopyLoop_32b)
    }
    char_count1 := AndI(char_count).Imm(0xF).u64
  }
  src_data3 := Phi(src_data, src_data2).ptr
  dst_data3 := Phi(dst_data, dst_data2).ptr
  char_count2 := Phi(char_count, char_count1).u64

  # Copy 16-byte chunk (if any) compressing it into 8-byte chunk
  If(char_count2, 8).AE.Likely.b {
    Intrinsic(:COMPRESS_EIGHT_UTF16_TO_UTF8_CHARS_USING_SIMD, src_data3, dst_data3).void
    src_data4 := AddI(src_data3).Imm(16).ptr
    dst_data4 := AddI(dst_data3).Imm(8).ptr
  }
  src_data5 := Phi(src_data3, src_data4).ptr
  dst_data5 := Phi(dst_data3, dst_data4).ptr
  # Copy 2-byte chunks compressing them into 1-byte
  n_2b := AndI(char_count2).Imm(7).u64
  If(n_2b, 0).A.Likely.b {
    j1 := Cast(0).u64
Label(:CopyLoop_2b)
    j := Phi(j1, j2).u64
    Store(dst_data5, j, Load(src_data5, ShlI(j).Imm(1).u64).u8).u8
    j2 := AddI(j).Imm(1).u64
    If(j2, n_2b).B.Likely.b {
      Goto(:CopyLoop_2b)
    }
  }
else  # if Options.arch == :arm64
  # Copy 8-byte chunks compressing them into 4-byte chunks
  n_8b := ShrI(char_count).Imm(2).u64
  If(n_8b, 0).A.Likely.b {
    i1 := Cast(0).u64
Label(:CopyLoop_8b)
    i := Phi(i1, i2).u64
    chunk := Load(src_data, ShlI(i).Imm(3).u64).u64
    chunk := AndI(chunk).Imm(0x00ff00ff00ff00ff).u64 # zero high part of each two-byte
    chunk := AndI(Or(chunk, ShrI(chunk).Imm(8).u64).u64).Imm(0x0000ffff0000ffff).u64
    chunk := Or(chunk, ShrI(chunk).Imm(16).u64).u64
    Store(dst_data, ShlI(i).Imm(2).u64, Cast(chunk).u32).u32
    i2 := AddI(i).Imm(1).u64
    If(i2, n_8b).B.Likely.b {
      Goto(:CopyLoop_8b)
    }
  }
  # Copy 2-byte chunks compressing them into 1-byte
  If(AndI(char_count).Imm(3).u64, 0).A.Likely.b {
    j1 := ShlI(n_8b).Imm(2).u64  # number of already copied chars if any
Label(:CopyLoop_2b)
    j := Phi(j1, j2).u64
    Store(dst_data, j, Load(src_data, ShlI(j).Imm(1).u64).u8).u8
    j2 := AddI(j).Imm(1).u64
    If(j2, char_count).B.Likely.b {
      Goto(:CopyLoop_2b)
    }
  }
end  # if Options.arch == :arm64
end  # compress_u16_to_u8_chars

###
# Copy dwords (8-bytes)
#
scoped_macro(:copy_dwords) do |src, dst, size|
    count := AndI(size).Imm(~0x7).word
    i1 := Cast(0).word
Label(:CopyLoop_8b)
    i := Phi(i1, i2).word
    If(i, count).AE.Unlikely {
        Goto(:End)
    }
    Store(dst, i, Load(src, i).word).word
    i2 := AddI(i).Imm(8).word
    Goto(:CopyLoop_8b)
Label(:End)
end  # copy_dwords

###
# Copy u8 chars from src to dst
#
scoped_macro(:copy_u8_chars) do |src, dst, count|
    # Copy 8-byte chunks
    len := Cast(count).word
    copy_dwords(src, dst, len)

    # copy the tail if needed
    i1 := AndI(len).Imm(~0x7).word
Label(:CopyLoop)
    i := Phi(i1, i2).word
    If(i, len).AE.Unlikely {
        Goto(:End)
    }
    Store(dst, i, Load(src, i).u8).u8
    i2 := AddI(i).Imm(1).word
    Goto(:CopyLoop)

Label(:End)
end  # copy_u8_chars

###
# Copy u16 chars from src to dst
#
scoped_macro(:copy_u16_chars) do |src, dst, count|
    # Copy 8-byte chunks
    len := Cast(ShlI(count).Imm(1).u32).word
    copy_dwords(src, dst, len)

    # copy the tail if needed
    i1 := AndI(len).Imm(-8).u64
Label(:CopyLoop)
    i := Phi(i1, i2).u64
    If(i, len).AE.Unlikely.b {
        Goto(:End)
    }
    Store(dst, i, Load(src, i).u16).u16
    i2 := AddI(i).Imm(2).u64
    Goto(:CopyLoop)

Label(:End)
end  # copy_u16_chars

###
# Copy u8 chars expanding them to u16 chars
#
scoped_macro(:expand_u8_to_u16_chars) do |src, dst, count|
  i0 := Cast(0).u64
  len := Cast(count).u64
Label(:CopyLoop)
  i := Phi(i0, i1).u64
  If(i, len).AE.Unlikely.b {
      Goto(:End)
  }
  Store(dst, ShlI(i).Imm(1).u64, Cast(Load(src, i).u8).u16).u16
  i1 := AddI(i).Imm(1).u64
  Goto(:CopyLoop)
Label(:End)
end  # expand_u8_to_u16_chars

###
# Copy data from compressed string to array of utf16 chars
#
scoped_macro(:copy_compressed_string_to_array_of_chars) do |str_data, arr_data, char_count|
  # String contains 8-bit chars
  If(char_count, 0).A.Likely.b {
    i1 := Cast(0).u64
Label(:CopyLoop)
    i := Phi(i1, i2).u64
    Store(arr_data, ShlI(i).Imm(1).u64, Cast(Load(str_data, i).u8).u16).u16
    i2 := AddI(i).Imm(1).u64
    If(i2, char_count).B.Likely.b {
      Goto(:CopyLoop)
    }
  }
end  # copy_compressed_string_to_array_of_chars

# calculate the difference between string chunks
# stored in 64-bits numbers, byte/hword swap is
# required before comparison for the correct result

scoped_macro(:calculate_chars_difference_lat) do |d1, d2|
  ldata1 := Intrinsic(:REVERSE_BYTES_U64, d1).u64
  ldata2 := Intrinsic(:REVERSE_BYTES_U64, d2).u64
  ret := Cmp(ldata1, ldata2).i32
end  # calculate_chars_difference_lat

scoped_macro(:calculate_chars_difference_utf) do |d1, d2|
  udata1 := Bitcast(Intrinsic(:REVERSE_HALF_WORDS, Bitcast(d1).f64).f64).u64
  udata2 := Bitcast(Intrinsic(:REVERSE_HALF_WORDS, Bitcast(d2).f64).f64).u64
  ret := Cmp(udata1, udata2).i32
end  # calculate_chars_difference_utf

scoped_macro(:calculate_chars_difference) do |d1, d2, utf|
  data1 := Cast(d1).u64
  data2 := Cast(d2).u64

  If(utf, 0).EQ.b {
    cmp1 := calculate_chars_difference_lat(data1, data2)
  } Else {
    cmp2 := calculate_chars_difference_utf(data1, data2)
  }
  ret := Phi(cmp1, cmp2).i32
end  # calculate_chars_difference

scoped_macro(:compare_LU_strings) do |lat, utf, len|
  # considering the data buffer to be allocated to
  # 8-bytes alignment, we can safely read 8-bytes chunks
  last_idx := SubI(len).Imm(4).i64
  i1 := 0
Label(:Loop)
  i := Phi(i1, i2).i64
  If(i, last_idx).GE.Unlikely.b {
    # can safely read 8 bytes behind - length and hashcode
    junk_bits := ShlI(Sub(i, last_idx).u64).Imm(4).u64
    last_lv := Load(lat, last_idx).u32
    last_v := Shr(Bitcast(Intrinsic(:EXPAND_U8_TO_U16, Bitcast(last_lv).f32).f64).u64, junk_bits).u64
    last_u := Shr(Load(utf, ShlI(last_idx).Imm(1).u64).u64, junk_bits).u64
    If(last_v, last_u).NE.b {
      Goto(:NotEqual)
    }
    Goto(:End)
  }

  lv := Load(lat, i).u32
  v := Bitcast(Intrinsic(:EXPAND_U8_TO_U16, Bitcast(lv).f32).f64).u64
  u := Load(utf, ShlI(i).Imm(1).u64).u64
  If(v, u).NE.b {
    Goto(:NotEqual)
  }
  i2 := AddI(i).Imm(4).i64
  Goto(:Loop)

  # the version assuming 128-bits types support
  #
  # v := Intrinsic(:EXPAND_U8_TO_U16, Load(lat, i).f64).f128
  # u := Load(utf, i).f128
  # v1 = Intrinsic(:GET_LOW_PART, v).u64
  # u1 = Intrinsic(:GET_LOW_PART, u).u64
  # n11 := Bitcast(v1).u64
  # n21 := Bitcast(u1).u64
  # If(n11, n21).NE.b {
  #   d11 := Bitcast(Intrinsic(:REVERSE_HALF_WORDS, v1).f64).u64
  #   d21 := Bitcast(Intrinsic(:REVERSE_HALF_WORDS, u1).f64).u64
  #   Goto(:NotEqual)
  # }
  # v2 = Intrinsic(:GET_HIGH_PART, v).u64
  # u2 = Intrinsic(:GET_HIGH_PART, u).u64
  # n12 := Bitcast(v2).u64
  # n22 := Bitcast(u2).u64
  # If(n12, n22).NE.b {
  #   d12 := Bitcast(Intrinsic(:REVERSE_HALF_WORDS, v2).f64).u64
  #   d22 := Bitcast(Intrinsic(:REVERSE_HALF_WORDS, u2).f64).u64
  #   Goto(:NotEqual)
  # }
  #
  # Label(:NotEqual)
  # d1 := Phi(d11, d12)
  # d2 := Phi(d21, d22)
  # res := Sub(d1, d2).u64

Label(:NotEqual)
  v_ne := Phi(last_v, v).u64
  u_ne := Phi(last_u, u).u64
  ret_ne := calculate_chars_difference_utf(v_ne, u_ne).i32
  Goto(:End)

Label(:End)
  # -1: the prefix is the same but the utf string has to be
  # longer as it would have had latin encoding otherwise
  ret := Phi(-1, ret_ne).i32
end  # compare_LU_strings

scoped_macro(:compare_mixed_strings) do |buf1, buf2, len, utf_is_first|
  If(utf_is_first, 0).EQ.b {
    ret1 := compare_LU_strings(buf1, buf2, len)
  } Else {
    ret2 := Neg(compare_LU_strings(buf2, buf1, len).i32).i32
  }
  ret := Phi(ret1, ret2).i32
end  # compare_mixed_strings

###
# Compute string hashcode
#
scoped_macro(:u8_string_hashcode) do |str_data, char_count|
  hash := Cast(0).u32
  If(char_count, 0).A.Likely.b {
    i1 := Cast(0).u32
    imm31 := Cast(31).u32
Label(:Loop_hash)
    hash1 := Phi(hash, hash2).u32
    i := Phi(i1, i2).u32
    ch := Cast(Load(str_data, i).u8).SrcType(Constants::COMPILER_UINT8).u32
    hash2 := Add(Mul(hash1, imm31).u32, ch).u32
    i2 := AddI(i).Imm(1).u32
    If(i2, char_count).B.Likely.b {
      Goto(:Loop_hash)
    }
  }
  hashcode := Phi(hash, hash2).u32
end  # u8_string_hashcode

scoped_macro(:u16_string_hashcode) do |str_data, char_count|
  hash := Cast(0).u32
  If(char_count, 0).A.Likely.b {
    i1 := Cast(0).u64
    imm31 := Cast(31).u32
    stop := ShlI(Cast(char_count).u64).Imm(1).u64
Label(:Loop_hash)
    hash1 := Phi(hash, hash2).u32
    i := Phi(i1, i2).u64
    ch := Cast(Load(str_data, i).u16).SrcType(Constants::COMPILER_UINT16).u32
    hash2 := Add(Mul(hash1, imm31).u32, ch).u32
    i2 := AddI(i).Imm(2).u64
    If(i2, stop).B.Likely.b {
      Goto(:Loop_hash)
    }
  }
  hashcode := Phi(hash, hash2).u32
end  # u16_string_hashcode

scoped_macro(:macroStringCompareTo) do |str1, str2|
  If(str1, str2).EQ.Unlikely.b {
    result_1 := 0
    Goto(:Done)
  }

  length1 := LoadI(str1).Imm(Constants::STRING_LENGTH_OFFSET).u32
  length2 := LoadI(str2).Imm(Constants::STRING_LENGTH_OFFSET).u32

  # cover the cases of length2 being zero and both lengths being zero
  If(length2, 0).EQ.Unlikely.b {
    result_2 := length1
    Goto(:Done)
  }

  If(length1, 0).EQ.Unlikely.b {
    result_3 := -1
    Goto(:Done)
  }

  buf1 := AddI(str1).Imm(Constants::STRING_DATA_OFFSET).ptr
  buf2 := AddI(str2).Imm(Constants::STRING_DATA_OFFSET).ptr

  # get the least length in chars
  length := ShrI(Cast(Min(length1, length2).i32).u64).Imm(Constants::STRING_LENGTH_SHIFT).u64

  utf_1 := is_string_uncompressed_u32(length1)
  utf_2 := is_string_uncompressed_u32(length2)

  # in the unlikely case the strings are in different
  # encodings the comparison gets more comlicated as
  # we have to expand the latin string to u16 first
  If(utf_1, utf_2).NE.Unlikely.b {
    result_4 := compare_mixed_strings(buf1, buf2, length, utf_1).i32
    Goto(:Done)
  }
  utf := Cast(utf_1).u64

  # make length be in actual bytes now
  length := Shl(length, utf).u64

  # considering the data buffer to be allocated to
  # 8-bytes alignment, we can safely read 8-bytes chunks
  last_idx := SubI(length).Imm(8).i64
  i1 := 0
Label(:Loop)
  i := Phi(i1, i2).i64
  If(i, last_idx).GE.Unlikely.b {
    # can safely read 8 bytes behind - length and hashcode
    junk_bits := ShlI(Sub(i, last_idx).u64).Imm(3).u64
    last_data1 := Shr(Load(buf1, last_idx).u64, junk_bits).u64
    last_data2 := Shr(Load(buf2, last_idx).u64, junk_bits).u64
    If(last_data1, last_data2).NE.b {
      Goto(:NotEqual)
    }
    result_5 := Sub(length1, length2).i32
    Goto(:Done)
  }

  data1 := Load(buf1, i).u64
  data2 := Load(buf2, i).u64
  If(data1, data2).NE.b {
    Goto(:NotEqual)
  }
  i2 := AddI(i).Imm(8).i64
  Goto(:Loop)

Label(:NotEqual)
  d1 := Phi(last_data1, data1).u64
  d2 := Phi(last_data2, data2).u64
  result_6 := calculate_chars_difference(d1, d2, utf).i32

Label(:Done)
  result := Phi(result_1, result_2, result_3, result_4, result_5, result_6).i32
end  # macroStringCompareTo

##
# GenerateStringEquals is used as a macro in plugins (ets, ecmascript, etc.) and therefore must be placed in the
# `string_helpers.irt` file instead of the `string.irt` one because the former file may be included in irtoc scripts
# provided by plugins to invoke the `GenerateStringEquals` with the corresponding value of the `lang` parameter,
# example:
#
# GenerateStringEquals(lang='ets', dynamic=false, :FastPath)
#
# It is assumed that the runtime supports the string compression feature
# and the feature is always enabled (see runtime/runtime.cpp `InitializePandaVM()`).
#
def GenerateStringEquals(lang, dynamic, cgmode = :FastPath)
    suffix = (cgmode == :NativePlus ? 'NativePlus': '')
    mode = (dynamic ? [:FastPath, :DynamicMethod, :DynamicStub] : [cgmode] )

    # For the ARM64 target NativePlus mode needs more
    # registers left for the codegen to work correctly
    reg_mask = Options.arch == :arm64 ? $panda_mask : RegMask.new($full_regmap, :arg0, :arg1, :callee0, :caller1)

    function("#{lang}StringEquals#{suffix}".to_sym,
            params: {str1_orig: 'ref', str2_orig: 'ref'},
            regmap: $full_regmap,
            regalloc_set: reg_mask,
            mode: mode,
            lang: lang.empty? ? 'PANDA_ASSEMBLY' : lang.upcase) {
        # Arm32 is not supported
        if Options.arch == :arm32
            Intrinsic(:UNREACHABLE).void.Terminator
            next
        end
        If(str1_orig, str2_orig).EQ.Unlikely.b {
            Return(1).b
        }
        unless dynamic
            If(str1_orig, 0).EQ.Unlikely.b {
                Goto(:NotEqual)
            }
            If(str2_orig, 0).EQ.Unlikely.b {
                Goto(:NotEqual)
            }
        end
        if cgmode == :NativePlus
            str1 := try_use_cached_flat_str_reject_sliced(str1_orig, AsGlobalLabel(:SlowPathEntrypoint))
        else
            check_not_tree_string_type(str1_orig) if defines.DEBUG
            # it still can be slice
            check_string_type(str1_orig, AsGlobalLabel(:SlowPathEntrypoint))
            str1 := str1_orig
        end
        str2 := try_use_cached_flat_str_reject_sliced(str2_orig, AsGlobalLabel(:SlowPathEntrypoint))
        if dynamic
            length1 := LoadI(str1).Imm(Constants::STRING_LENGTH_OFFSET).u32
            length2 := LoadI(str2).Imm(Constants::STRING_LENGTH_OFFSET).u32
            length1 := AndI(length1).Imm("~(2U)").u32
            length2 := AndI(length2).Imm("~(2U)").u32
            If(length1, length2).NE.Unlikely.b {
                Goto(:NotEqual)
            }
            length := Cast(length1.u32).u64
        else
            class1 := load_class(str1)
            class2 := load_class(str2)
            If(class1, class2).NE.Unlikely.b {
                Goto(:NotEqual)
            }
            length1 := LoadI(str1).Imm(Constants::STRING_LENGTH_OFFSET).u32
            length2 := LoadI(str2).Imm(Constants::STRING_LENGTH_OFFSET).u32
            If(length1, length2).NE.Unlikely.b {
                Goto(:NotEqual)
            }
            length := Cast(length1.u32).u64
        end
        length := unpack_length_with_compression(length, Constants::STRING_LENGTH_SHIFT)
        If(length, 8).GT.b {
            Goto(:Long)
        }
        odd_bytes := Sub(8, length).u64
        last_idx := Sub(Constants::STRING_DATA_OFFSET, odd_bytes).u64
        buf1 := Load(str1, last_idx).u64
        buf2 := Load(str2, last_idx).u64
        odd_bits := Shl(odd_bytes, 3).u64
        diff := Shr(Xor(buf1, buf2).u64, odd_bits).u64
        res := Compare(diff, 0).EQ.b
        if dynamic
            # If length is 0, odd_bits is 64 and Shr above does nothing, so we
            # effectively compare last 8 bytes of two strings before their data
            # (length and hash code). Hash code for empty string is always 0,
            # but value stored in length field of equal strings can be different
            # in dynamic implementation, so we check (length == 0) separately
            res := Or(res, Compare(length, 0).EQ.b).b
        end
        Return(res).b

    Label(:Long)
        hashcode1 := LoadI(str1).Imm(Constants::STRING_HASHCODE_OFFSET).u32
        If(hashcode1, 0).NE.b {
            hashcode2 := LoadI(str2).Imm(Constants::STRING_HASHCODE_OFFSET).u32
            If(hashcode2, 0).NE.b {
                If(hashcode1, hashcode2).NE.b {
                    Goto(:NotEqual)
                }
            }
        }

        unroll := Compare(length, 64).GE.b
        IfImm(unroll).Imm(0).SrcType("DataType::BOOL").NE.b {
          LiveOut(str1).DstReg(regmap[:arg0]).ref
          LiveOut(str2).DstReg(regmap[:arg1]).ref
          Intrinsic(:TAIL_CALL).AddImm(get_entrypoint_offset('STRING_EQUALS_UNROLL')).MethodAsImm('StringEqualsUnroll').Terminator.b
        }
        first_idx := Constants::STRING_DATA_OFFSET
        last_idx := Sub(Add(first_idx, length).u64, 8).u64

    Label(:Loop)
        idx := Phi(first_idx, next_idx).u64
        buf1 := Load(str1, idx).u64
        buf2 := Load(str2, idx).u64
        If(buf1, buf2).NE.Unlikely.b {
            Goto(:NotEqual)
        }
        next_idx := Add(idx, 8).u64
        If(next_idx, last_idx).GE.Unlikely.b {
            buf1 := Load(str1, last_idx).u64
            buf2 := Load(str2, last_idx).u64
            res := Compare(buf1, buf2).EQ.b
            Return(res).b
        }
        Goto(:Loop)
    Label(:NotEqual)
        Return(0).b
    LabelGlobal(:SlowPathEntrypoint)
      if cgmode == :NativePlus
        method = "#{lang.empty? ? 'Core' : lang}StringEqualsEntrypoint"
        Return(Call(str1_orig, str2_orig).Method(method).b).b
      else
        entrypoint = get_entrypoint_offset("#{lang.empty? ? '' : lang.upcase + '_'}STRING_EQUALS_SLOW_PATH")
        entrypoint_bridge = "#{lang.empty? ? '' : lang}StringEqualsUsualBridge"
        Intrinsic(:SLOW_PATH_ENTRY, str1_orig, str2_orig).AddImm(entrypoint).MethodAsImm(entrypoint_bridge).Terminator.b
        Intrinsic(:UNREACHABLE).Terminator.void if defines.DEBUG
      end
    }
end
